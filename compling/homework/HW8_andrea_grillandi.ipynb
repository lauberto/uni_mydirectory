{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8_andrea_grillandi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjLG/GydS8L0Le7GboQnjh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauberto/uni_mydirectory/blob/master/compling/homework/HW8_andrea_grillandi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5isXtrH4YOAK",
        "colab_type": "code",
        "outputId": "f74415e4-3d98-4fcd-a810-01672aaf466c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZqXm2D5YS_O",
        "colab_type": "code",
        "outputId": "98d4fbe8-2619-4e02-9705-1a39683ad21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l9i8sdcA2CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json, os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "morph = MorphAnalyzer()\n",
        "stops = set(stopwords.words('russian'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZC7vgNIBQwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "punct = punctuation+'«»—…“”*№–'\n",
        "stops = set(stopwords.words('russian'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUgbOPQQ2BDS",
        "colab_type": "code",
        "outputId": "0456a574-415a-4c0b-afdc-fa5229b2a5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgNr213zwo7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_DATA = os.path.join(os.getcwd(), 'drive', 'My Drive', 'ru_kw_eval_datasets', 'data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95iGq7P85_1q",
        "colab_type": "code",
        "outputId": "b9742351-7c90-4192-9c75-392ebed81b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "os.listdir(PATH_TO_DATA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cyberleninka_4.jsonlines.zip',\n",
              " 'russia_today_7.jsonlines.zip',\n",
              " 'cyberleninka_0.jsonlines.zip',\n",
              " 'cyberleninka_1.jsonlines.zip',\n",
              " 'cyberleninka_2.jsonlines.zip',\n",
              " 'cyberleninka_3.jsonlines.zip',\n",
              " 'habrahabr_0.jsonlines.zip',\n",
              " 'habrahabr_1.jsonlines.zip',\n",
              " 'habrahabr_2.jsonlines.zip',\n",
              " 'habrahabr_3.jsonlines.zip',\n",
              " 'ng_0.jsonlines.zip',\n",
              " 'ng_1.jsonlines.zip',\n",
              " 'russia_today_0.jsonlines.zip',\n",
              " 'russia_today_1.jsonlines.zip',\n",
              " 'russia_today_2.jsonlines.zip',\n",
              " 'russia_today_3.jsonlines.zip',\n",
              " 'russia_today_4.jsonlines.zip',\n",
              " 'russia_today_5.jsonlines.zip',\n",
              " 'russia_today_6.jsonlines.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1vYkNNx3hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnbQ_ivRx763",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntY-q3au8F1X",
        "colab_type": "code",
        "outputId": "16b1bde5-414c-4ee1-a74e-0f804675aa9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17266, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZrN6f778iGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(true_kws, predicted_kws):\n",
        "    assert len(true_kws) == len(predicted_kws)\n",
        "    \n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1s = []\n",
        "    jaccards = []\n",
        "    \n",
        "    for i in range(len(true_kws)):\n",
        "        \n",
        "        true_kw = set(true_kws[i])\n",
        "        if predicted_kws[i]:\n",
        "          predicted_kw = set(predicted_kws[i])\n",
        "        else:\n",
        "          predicted_kw=set()\n",
        "        \n",
        "        tp = len(true_kw & predicted_kw)\n",
        "        union = len(true_kw | predicted_kw)\n",
        "        fp = len(predicted_kw - true_kw)\n",
        "        fn = len(true_kw - predicted_kw)\n",
        "        \n",
        "        if (tp+fp) == 0:\n",
        "            prec = 0\n",
        "        else:\n",
        "            prec = tp / (tp + fp)\n",
        "        \n",
        "        if (tp+fn) == 0:\n",
        "            rec = 0\n",
        "        else:\n",
        "            rec = tp / (tp + fn)\n",
        "        if (prec+rec) == 0:\n",
        "            f1 = 0\n",
        "        else:\n",
        "            f1 = (2*(prec*rec))/(prec+rec)\n",
        "            \n",
        "        jac = tp / union\n",
        "        \n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        f1s.append(f1)\n",
        "        jaccards.append(jac)\n",
        "    print('Precision - ', round(np.mean(precisions), 2))\n",
        "    print('Recall - ', round(np.mean(recalls), 2))\n",
        "    print('F1 - ', round(np.mean(f1s), 2))\n",
        "    print('Jaccard - ', round(np.mean(jaccards), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8OkbuAl82ud",
        "colab_type": "code",
        "outputId": "b2664e4a-c3cc-4ae2-a85e-54e00e15c7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "evaluate(data['keywords'], data['keywords'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  1.0\n",
            "Recall -  1.0\n",
            "F1 -  1.0\n",
            "Jaccard -  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gGtkB67AfUX",
        "colab_type": "text"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJUwvKcBAss7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsXS8NDNAsvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer('russian')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT8Fyu3sAzZ6",
        "colab_type": "code",
        "outputId": "c09711e6-bcda-4945-a148-4886e211b800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stemmer.stem(\"собака\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'собак'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdQXpWi84gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(text):\n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [stemmer.stem(word) for word in words if word and word not in stops]\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbdcG6v5Cii5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['content_stem'] = data['content'].apply(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpRYYNJnXXim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['keywords_str'] = data['keywords'].apply(' '.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fub1Ie80DsSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['keywords_stem'] = data['keywords_str'].apply(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YZn6CxGC3qR",
        "colab_type": "code",
        "outputId": "089671d8-bb0c-4051-816e-ce17abedaebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "evaluate(data['keywords_stem'], data['content_stem'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.23\n",
            "Recall -  0.27\n",
            "F1 -  0.23\n",
            "Jaccard -  0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuMB24f6YjUz",
        "colab_type": "text"
      },
      "source": [
        "Стемминг немного улучшает метрики, однако надо учитывать то, что возможно разные слова одинаково стеммируются. При этом, полученные результаты могут чуть отличаться от реальных. Но, поскольку итоговая задача - понять о чем текст, вряд ли это сильно разрушает наш цель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoMPHPaMZ8dl",
        "colab_type": "text"
      },
      "source": [
        "### Стемминг + Tfidf\n",
        "Попробуем сложить с векторизацией Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJk7hLdlZ8SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['content_stem_str'] = data['content_stem'].apply(' '.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zwgC1kPagp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=5, max_df=0.7, max_features=750)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHIZA7GucKac",
        "colab_type": "code",
        "outputId": "fdcca0fa-8c05-402c-82be-f45b428424cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tfidf.fit(data['content_stem_str'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.7, max_features=750,\n",
              "                min_df=5, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BVbuH5kcKXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for i, word in enumerate(tfidf.get_feature_names())}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edVpoB4RcKTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_vectors = tfidf.transform(data['content_stem_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8bXOfxMdvZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kw_extraction(texts_vectors):\n",
        "  keywords=[]\n",
        "\n",
        "  for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])\n",
        "  return keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVWrX36Xdvcl",
        "colab_type": "code",
        "outputId": "c24bd080-c0ab-47f9-d634-f2f926e138db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "evaluate(data['keywords_stem'], kw_extraction(texts_vectors))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.13\n",
            "Recall -  0.13\n",
            "F1 -  0.12\n",
            "Jaccard -  0.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXrtbf_AeKQU",
        "colab_type": "text"
      },
      "source": [
        "Результат никак не улучшился, сейчас попробуем с теми же параметрами векторизации, но с чисто лемматизированными текстами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMTjmt8-ecwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
        "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
        "\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCFMVwneczr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['content_norm'] = data['content'].apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz0ONQ0becuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data['content_norm_str'] = data['content_norm'].apply(' '.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxW-kI3gBGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf.fit(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75-tpv-1gBJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for i, word in enumerate(tfidf.get_feature_names())}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_HIb2DDgRN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_vectors = tfidf.transform(data['content_norm_str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yFh7T4zgRV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(data['keywords'], kw_extraction(texts_vectors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc_1uZmVE4QC",
        "colab_type": "text"
      },
      "source": [
        "### Пересекающиеся окна и TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thONiclRX2UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPkrioGOj5z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_kws(text, window_size=5, random_p=0.1):\n",
        "\n",
        "    vocab = set(text)\n",
        "    word2id = {w:i for i, w in enumerate(vocab)}\n",
        "    id2word = {i:w for i, w in enumerate(vocab)}\n",
        "    ids = [word2id[word] for word in text]\n",
        "\n",
        "    m = np.zeros((len(vocab), len(vocab)))\n",
        "\n",
        "    for i in range(0, len(ids), 2): # here is the new step\n",
        "        window = ids[i:i+window_size]\n",
        "        \n",
        "        for j, k in combinations(window, 2):\n",
        "            m[j][k] += 1\n",
        "            m[k][j] += 1\n",
        "    \n",
        "    for i in range(m.shape[0]):\n",
        "        s = np.sum(m[i])\n",
        "        if not s:\n",
        "            continue\n",
        "        m[i] /= s\n",
        "    \n",
        "    pr = np.full((len(vocab), 1), 1)\n",
        "    d = 0.85 # d - это dumping factor,  which has the role of integrating into the model the probability of jumping from a given vertex to another random vertex in the graph\n",
        "    \n",
        "    for i in range(10):\n",
        "      pr = 0.15 + 0.85 * np.dot(m, pr)\n",
        "    pr = pr[:,0]\n",
        "    return [id2word[i] for i in pr.argsort()[:-11:-1]] # берем топ10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbOZsWe7oXQs",
        "colab_type": "code",
        "outputId": "861ab70e-dd02-4b1f-83f7-57ee31d0f469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "keywords_tr = data['content_norm'].apply(lambda x: get_kws(x, 5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 47s, sys: 2min 33s, total: 6min 21s\n",
            "Wall time: 3min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otbbbxEYHQ7N",
        "colab_type": "code",
        "outputId": "bfe52bdc-7e2e-4eda-97c3-9c9bb19cc428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "keywords_tr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [редактор, отношение, управление, арк, народ, ...\n",
              "1        [настоящее, предбайкалье, качество, заместител...\n",
              "2        [вычисление, порядок, автор, обзор, тип, центр...\n",
              "3        [век, молодая, разочарование, система, рыба, д...\n",
              "4        [право, лишение, слово, лишенец, провинция, ис...\n",
              "                               ...                        \n",
              "17261    [самолёт, комиссия, заместитель, руслан, самол...\n",
              "17262    [рынок, шутка, движение, лидер, криптоинвестор...\n",
              "17263    [звезда, создание, цель, облако, голограмма, в...\n",
              "17264    [состав, школа, количество, чемпионат, секрет,...\n",
              "17265    [объединение, политик, митинг, гражданин, сутк...\n",
              "Name: content_norm, Length: 17266, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox4p83y7oXWS",
        "colab_type": "code",
        "outputId": "64ecdbd1-6465-45f7-c5ee-a3f9bdded59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "evaluate(data['keywords'], keywords_tr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.02\n",
            "Recall -  0.03\n",
            "F1 -  0.02\n",
            "Jaccard -  0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O--B0oy7Hbcj",
        "colab_type": "text"
      },
      "source": [
        "Видимо, этот алгоритм очень плохо работает, возможно надо было отфилтрировать слова по частоте или по POS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcIZliAUoXNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_kws_old(text, top=5, window_size=5, random_p=0.1):\n",
        "\n",
        "    vocab = set(text)\n",
        "    if len(vocab)!=0:\n",
        "      word2id = {w:i for i, w in enumerate(vocab)}\n",
        "      id2word = {i:w for i, w in enumerate(vocab)}\n",
        "      ids = [word2id[word] for word in text]\n",
        "\n",
        "      m = np.zeros((len(vocab), len(vocab)))\n",
        "\n",
        "      for i in range(0, len(ids), 2):\n",
        "          window = ids[i:i+window_size]\n",
        "          \n",
        "          for j, k in combinations(window, 2): \n",
        "              m[j][k] += 1\n",
        "              m[k][j] += 1\n",
        "      \n",
        "      for i in range(m.shape[0]):\n",
        "          s = np.sum(m[i])\n",
        "          if not s:\n",
        "              continue\n",
        "          m[i] /= s\n",
        "      \n",
        "      c = Counter()\n",
        "\n",
        "      if len(vocab)!=0:\n",
        "        n = np.random.choice(len(vocab))\n",
        "      else:\n",
        "        n = np.random.choice(1000)\n",
        "      for i in range(500): \n",
        "          \n",
        "          go_random = np.random.choice([0, 1], p=[1-random_p, random_p])\n",
        "          \n",
        "          if go_random:\n",
        "              n = np.random.choice(len(vocab))\n",
        "          \n",
        "          n = take_step(n, m)\n",
        "          c.update([n])\n",
        "      \n",
        "      return [id2word[i] for i, count in c.most_common(top)]\n",
        "    else:\n",
        "      print(\"Let's skip this\")\n",
        "\n",
        "def take_step(n, matrix):\n",
        "    rang = len(matrix[n])\n",
        "    if np.any(matrix[n]):\n",
        "        next_n = np.random.choice(range(rang), p=matrix[n])\n",
        "    else:\n",
        "        next_n = np.random.choice(range(rang))\n",
        "    return next_n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOTrr86aHy5p",
        "colab_type": "code",
        "outputId": "73299308-db99-45e4-ba4a-03506ae4f7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%%time\n",
        "keywords_tr_old = data['content_norm'].apply(lambda x: get_kws_old(x, 10, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "Let's skip this\n",
            "CPU times: user 19min 44s, sys: 4.68 s, total: 19min 49s\n",
            "Wall time: 19min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mwXqucvH6Ow",
        "colab_type": "code",
        "outputId": "1d3b110d-e057-4d3c-bbb0-c6aae6628749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "evaluate(data['keywords'], keywords_tr_old)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.09\n",
            "Recall -  0.11\n",
            "F1 -  0.09\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiSC9WdAUdDf",
        "colab_type": "text"
      },
      "source": [
        "Опять такой вид алгоритм, где строяися матрицы из грязных текстов не так хорошо работает. Это мне кажется связан с тем, что в текстах много \"шума\" и перед таким алгоритмом надо было бы их перепредобрабатывать. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsLWvDP9INIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}