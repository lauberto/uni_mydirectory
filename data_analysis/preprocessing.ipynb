{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_analysis_preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7Obh+XWHOJ4Ffq6x4vvmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauberto/uni_mydirectory/blob/master/data_analysis/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUVwhkcz58ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "259f414f-3040-47a1-9437-372a9496e3b1"
      },
      "source": [
        "# !pip install pyspellchecker"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXdZCVXpL1ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install HanTa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jpGBfPxy4g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import pkg_resources\n",
        "from spellchecker import SpellChecker\n",
        "from HanTa import HanoverTagger as ht"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsLD6qRy2h22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "38215674-ec32-490e-928d-86bc85b9ab5a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MMRZIna4dhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bd0a1092-0a7c-4cf6-bdfc-5edef33e7f56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9nlEXVP6_wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENGLISH_DATASET = os.path.join(os.getcwd(), 'drive', 'My Drive', 'data_analysis_project', 'data', 'english_dataset.tsv')\n",
        "GERMAN_DATASET = os.path.join(os.getcwd(), 'drive', 'My Drive', 'data_analysis_project', 'data', 'german_dataset.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_w7YCAM-MD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENGLISH_DATASET_NEW = os.path.join(os.getcwd(), 'drive', 'My Drive', 'data_analysis_project', 'data', 'english_dataset_project.tsv')\n",
        "GERMAN_DATASET_NEW = os.path.join(os.getcwd(), 'drive', 'My Drive', 'data_analysis_project', 'data', 'german_dataset_project.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4yKids04d-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_url(x):\n",
        "    result = re.sub(r\"http\\S+\", \"url\", x)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5blIVFH5iv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_names(x):\n",
        "    for word in x.split():\n",
        "        if word[0] == \"@\":\n",
        "            x = x.replace(word, \"\")\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-COyUT8wIJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_punctuation(x):\n",
        "    replace_count = 0\n",
        "    text_len = len(x)\n",
        "    puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#',\n",
        "              '*', '+', '\\\\', '•', '~', '@', '£',\n",
        "              '·', '_', '{', '}', '©', '^', '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â',\n",
        "              '█', '½', 'à', '…',\n",
        "              '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―',\n",
        "              '¥', '▓', '—', '‹', '─',\n",
        "              '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸',\n",
        "              '¾', 'Ã', '⋅', '‘', '∞',\n",
        "              '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "              '¹', '≤', '‡', '√', ]\n",
        "\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        for letter in x:\n",
        "            if letter == punct:\n",
        "                replace_count += 1\n",
        "            else:\n",
        "                continue\n",
        "    return replace_count/text_len # return frequency of punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBltxAL5lux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(x):\n",
        "    replace_count = 0\n",
        "    puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#',\n",
        "              '*', '+', '\\\\', '•', '~', '@', '£',\n",
        "              '·', '_', '{', '}', '©', '^', '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â',\n",
        "              '█', '½', 'à', '…',\n",
        "              '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―',\n",
        "              '¥', '▓', '—', '‹', '─',\n",
        "              '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸',\n",
        "              '¾', 'Ã', '⋅', '‘', '∞',\n",
        "              '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "              '¹', '≤', '‡', '√', ]\n",
        "\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MQAf7Zc2MBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spellcheck(x):\n",
        "  spell = SpellChecker()\n",
        "  text = word_tokenize(x)\n",
        "  misspelled = spell.unknown(text)\n",
        "  return len(misspelled)/len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anWsP7kJ0Ljr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk pos_tags for english\n",
        "nouns = ['NN', 'NNS']\n",
        "proper_nouns = ['NNP', 'NNPS']\n",
        "adjectives = ['JJ', 'JJR', 'JJS']\n",
        "verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQAflhSCH2sB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pos_tags for german\n",
        "nouns_ger = ['NA', 'NN']\n",
        "proper_nouns_ger = ['NE']\n",
        "adjectives_ger = ['ADJA', 'ADJD']\n",
        "verbs_ger = ['VVFIN', 'VVIMP', 'VVINF', 'VVPP']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHAsmop66HMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pos_counter(x, tag_list):\n",
        "  count = 0\n",
        "  text = word_tokenize(x)\n",
        "  tags = nltk.pos_tag(text)\n",
        "  for tag in tags:\n",
        "    if tag[1] in tag_list:\n",
        "      count += 1\n",
        "  return count/len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-YNhF4OHyUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pos_counter_german(x, tag_list):\n",
        "  count = 0\n",
        "  text = word_tokenize(x)\n",
        "  tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
        "  tags = tagger.tag_sent(text)\n",
        "  for tag in tags:\n",
        "    if tag[2] in tag_list:\n",
        "      count += 1\n",
        "  return count/len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnGtGAbi5n0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_english = pd.read_csv(ENGLISH_DATASET, sep='\\t', names=['text_id', 'text', 'task_1', 'task_2', 'task_3'])\n",
        "full_german = pd.read_csv(GERMAN_DATASET, sep='\\t', names=['text_id', 'text', 'task_1', 'task_2', 'task_3'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5QOppN5yB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_english():\n",
        "  print('Removing urls')\n",
        "  full_english['text'] = full_english['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "  print('Removing names')\n",
        "  full_english['text'] = full_english['text'].apply(lambda x: remove_names(x))\n",
        "\n",
        "  print('Converting to lower case')\n",
        "  full_english['text'] = full_english['text'].str.lower()\n",
        "\n",
        "  print('Counting punctuation')\n",
        "  full_english['punct_freq'] = full_english['text'].apply(lambda x: count_punctuation(x))\n",
        "\n",
        "  print('Removing punctuation')\n",
        "  full_english['text'] = full_english['text'].apply(lambda x: remove_names(x))\n",
        "\n",
        "  print('Counting mistakes')\n",
        "  full_english['misspell_count'] = full_english['text'].apply(lambda x: spellcheck(x))\n",
        "\n",
        "  print('Counting pos for english')\n",
        "  full_english['noun_freq'] = full_english['text'].apply(lambda x: pos_counter(x, nouns))\n",
        "  full_english['propnoun_freq'] = full_english['text'].apply(lambda x: pos_counter(x, proper_nouns))\n",
        "  full_english['adj_freq'] = full_english['text'].apply(lambda x: pos_counter(x, adjectives))\n",
        "  full_english['verb_freq'] = full_english['text'].apply(lambda x: pos_counter(x, verbs))\n",
        "\n",
        "  print(full_english.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-EI4kle7Kln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f9e3967a-2fe2-4f92-e396-87ba005813ba"
      },
      "source": [
        "# preprocessing_english()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing urls\n",
            "Removing names\n",
            "Converting to lower case\n",
            "Counting punctuation\n",
            "Removing punctuation\n",
            "Counting mistakes\n",
            "Counting pos for english\n",
            "      text_id  ... verb_freq\n",
            "0     text_id  ...  0.000000\n",
            "1  hasoc_en_1  ...  0.195122\n",
            "2  hasoc_en_2  ...  0.190476\n",
            "3  hasoc_en_3  ...  0.120000\n",
            "4  hasoc_en_4  ...  0.142857\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQyi-1Az-_sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_german():\n",
        "  print('Removing urls')\n",
        "  full_german['text'] = full_german['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "  print('Removing names')\n",
        "  full_german['text'] = full_german['text'].apply(lambda x: remove_names(x))\n",
        "\n",
        "  print('Converting to lower case')\n",
        "  full_german['text'] = full_german['text'].str.lower()\n",
        "\n",
        "  print(full_german.shape)\n",
        "  full_german['text'].replace('', np.nan, inplace=True)\n",
        "  full_german.dropna(subset=['text'], inplace=True)\n",
        "  print(full_german.shape)\n",
        "\n",
        "  print('Counting punctuation')\n",
        "  full_german['punct_freq'] = full_german['text'].apply(lambda x: count_punctuation(x))\n",
        "\n",
        "  print('Removing punctuation')\n",
        "  full_german['text'] = full_german['text'].apply(lambda x: remove_names(x))\n",
        "\n",
        "  print('Counting mistakes')\n",
        "  full_german['misspell_count'] = full_german['text'].apply(lambda x: spellcheck(x))\n",
        "\n",
        "  print('Counting pos for german')\n",
        "  full_german['noun_freq'] = full_german['text'].apply(lambda x: pos_counter_german(x, nouns_ger))\n",
        "  full_german['propnoun_freq'] = full_german['text'].apply(lambda x: pos_counter_german(x, proper_nouns_ger))\n",
        "  full_german['adj_freq'] = full_german['text'].apply(lambda x: pos_counter_german(x, adjectives_ger))\n",
        "  full_german['verb_freq'] = full_german['text'].apply(lambda x: pos_counter_german(x, verbs_ger))\n",
        "\n",
        "  print(full_german.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0fSqRAr_YMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "91e06343-18a1-47d1-8f10-4aa661266fcf"
      },
      "source": [
        "# preprocessing_german()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing urls\n",
            "Removing names\n",
            "Converting to lower case\n",
            "(3819, 7)\n",
            "(3819, 7)\n",
            "Counting punctuation\n",
            "Removing punctuation\n",
            "Counting mistakes\n",
            "Counting pos for german\n",
            "      text_id  ... verb_freq\n",
            "0     text_id  ...  0.000000\n",
            "1  hasoc_de_1  ...  0.125000\n",
            "2  hasoc_de_2  ...  0.153846\n",
            "3  hasoc_de_3  ...  0.095238\n",
            "4  hasoc_de_4  ...  0.027027\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIkkLAN9775j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full_english.to_csv(ENGLISH_DATASET_NEW, sep='\\t', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23NN4l27-WZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full_german.to_csv(GERMAN_DATASET_NEW, sep='\\t', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}